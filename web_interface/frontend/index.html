<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Poetry Matchmaker</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <div class="theme-switcher" id="themeSwitcher">🌙</div>
  <div class="our-method-trigger" id="ourMethodTrigger">How This Works ✨</div>
  <div class="mode-switcher" id="modeSwitcher">
    <span class="mode selected" data-mode="microphone">Speak Your Heart</span>
    <span class="slash">/</span>
    <span class="mode" data-mode="keyboard">Pen Your Thoughts</span>
  </div>
  <div class="attract" id="attractBtn">What's stirring in your heart today?</div>

  <div class="loading-overlay" id="loadingOverlay">
    <!-- Spinner div removed -->
    <div class="loading-text" id="loadingText">Finding your perfect poem...</div>
     <div class="loading-bar-container">
      <div class="loading-bar" id="loadingBar"></div>
    </div>
    <div class="loading-subtext" id="loadingSubtext">Searching worlds of verse...</div>
  </div>

  <!-- Modal HTML Structure -->
  <div class="modal-overlay" id="ourMethodModalOverlay">
    <div class="modal-content">
      <span class="modal-close-btn" id="ourMethodModalCloseBtn">&times;</span>
      <h2>The Heart of Our Poetry Engine</h2>
      <p>Ever wonder how we find that perfect verse to echo your innermost feelings? It's a blend of poetic intuition and thoughtful technology, designed for everyone from the curious reader to the tech-savvy explorer.</p>

      <h3>For the Lover of Words:</h3>
      <p>Imagine whispering your mood, a fleeting thought, or a deep emotion. Our digital muse listens, not just for words, but for the feeling behind them. It then journeys through a vast library of poetry, seeking verses that resonate with that unique emotional signature. The poem chosen for you is one our AI believes truly captures the essence of what you shared, offering a moment of connection and understanding.</p>

      <h3>For the Tech-Curious Mind:</h3>
      <p>Our process begins by transforming your textual or transcribed audio input into a rich numerical representation called an <code_inline>embedding</code_inline>. This captures the semantic essence of your query. We then use this embedding to perform a similarity search against a pre-indexed database of poems (also converted into embeddings), retrieving the top 22 most contextually relevant poems.</p>
      <p>But we don't stop there. Each of these 22 candidates is then presented to an advanced Large Language Model (LLM, specifically GPT-4.1). The LLM scores each poem based on its relevance, nuance, and emotional resonance with your original query, also providing a qualitative explanation for its top choice. This two-stage process—broad semantic search followed by deep LLM-driven evaluation—allows for a uniquely sensitive and accurate matching of poetry to your expressed state.</p>

      <h3>Why This Approach?</h3>
      <p>Many poetry finders rely on simple keywords or predefined tags. We aim for something deeper: a connection based on the authentic feeling and meaning you express. By combining the breadth of embedding search with the nuanced understanding of a sophisticated LLM, we hope to offer you not just any poem, but a poem that truly speaks to you.</p>
    </div>
  </div>

  <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
  <script src="https://unpkg.com/gsap@3/dist/gsap.min.js"></script>
  <script>
    // Mouse attraction setup
    const attractBtn = document.getElementById('attractBtn');
    const MAX_OFFSET = 8;

    function mouseAttract(el, maxOffset = 8) {
      const rect = () => el.getBoundingClientRect();
      const center = () => {
        const r = rect();
        return {
          x: r.left + r.width / 2,
          y: r.top + r.height / 2
        };
      };

      const setX = gsap.quickTo(el, "x", { duration: 0.5, ease: "power3.out" });
      const setY = gsap.quickTo(el, "y", { duration: 0.5, ease: "power3.out" });

      function onMove(e) {
        const c = center();
        const dx = e.clientX - c.x;
        const dy = e.clientY - c.y;
        const dist = Math.sqrt(dx * dx + dy * dy) || 1;
        const maxDist = Math.sqrt(window.innerWidth ** 2 + window.innerHeight ** 2);
        const factor = Math.min(dist / (maxDist / maxOffset), 1);
        const angle = Math.atan2(dy, dx);
        const x = Math.cos(angle) * factor * maxOffset;
        const y = Math.sin(angle) * factor * maxOffset;
        setX(x);
        setY(y);
      }

      window.addEventListener("mousemove", onMove);
      return () => {
        window.removeEventListener("mousemove", onMove);
        setX(0);
        setY(0);
      };
    }

    mouseAttract(attractBtn, MAX_OFFSET);

    // Mode switching and interaction
    const modeSwitcher = document.getElementById('modeSwitcher');
    const themeSwitcher = document.getElementById('themeSwitcher');
    const modeSpans = modeSwitcher.querySelectorAll('.mode');
    const loadingOverlay = document.getElementById('loadingOverlay');
    let currentMode = 'microphone';
    let expanded = false;
    let recording = false;
    let mediaRecorder = null;
    let audioChunks = [];
    let currentTheme = 'dark';

    // Contemplative prompts that rotate
    const contemplativePrompts = [
      "What's stirring in your heart today?",
      "What truth wants to be spoken?",
      "What feeling seeks its poem?",
      "What's been quietly waiting to be heard?",
      "What would you like to remember about this moment?",
      "What emotion needs expression?",
      "What story lives within you right now?",
      "What unspoken verse resides within?"
    ];

    const typingPrompts = [
      "Type what's stirring in your heart...",
      "Share what truth wants to be spoken...",
      "Express what feeling seeks its poem...",
      "Write what's been quietly waiting...",
      "Capture what you'd like to remember...",
      "Put your emotions into words...",
      "Tell your story...",
      "Scribe the whispers of your heart..."
    ];

    let currentPromptIndex = 0;

    function getNextPrompt(isTyping = false) {
      const prompts = isTyping ? typingPrompts : contemplativePrompts;
      const prompt = prompts[currentPromptIndex];
      currentPromptIndex = (currentPromptIndex + 1) % prompts.length;
      return prompt;
    }

    function updateButtonText() {
      if (currentMode === 'microphone' && !recording) {
        attractBtn.textContent = getNextPrompt(false);
      } else if (currentMode === 'keyboard' && !expanded) {
        attractBtn.textContent = getNextPrompt(false);
      }
    }

    // Theme switching
    function toggleTheme() {
      currentTheme = currentTheme === 'dark' ? 'light' : 'dark';
      document.body.setAttribute('data-theme', currentTheme);
      themeSwitcher.textContent = currentTheme === 'dark' ? '🌙' : '☀️';
      
      // Save theme preference
      localStorage.setItem('poetry-theme', currentTheme);
    }

    // Load saved theme
    const savedTheme = localStorage.getItem('poetry-theme');
    if (savedTheme) {
      currentTheme = savedTheme;
      document.body.setAttribute('data-theme', currentTheme);
      themeSwitcher.textContent = currentTheme === 'dark' ? '🌙' : '☀️';
    }

    themeSwitcher.addEventListener('click', toggleTheme);

    // Initialize with first prompt
    updateButtonText();

    function showLoading() {
      loadingOverlay.style.display = 'flex';
      loadingOverlay.style.opacity = '1'; // Added this line
      updateLoadingProgress(0, "Finding your perfect poem...", "Searching worlds of verse...");
    }

    function hideLoading() {
      // This function might become redundant or less used if opacity handles hiding.
      // For now, direct opacity manipulation is used. If display:none is still needed,
      // it should be coordinated with the opacity transition.
      // For this subtask, we'll primarily use opacity for the transition out.
      loadingOverlay.style.opacity = '0';
      // To ensure it's hidden for accessibility and interaction after transition:
      setTimeout(() => {
        if (loadingOverlay.style.opacity === '0') { // Check if it wasn't re-shown
            loadingOverlay.style.display = 'none';
        }
      }, 500); // Match transition duration
    }

    function updateLoadingProgress(percentage, mainText, subText) {
      const loadingBar = document.getElementById('loadingBar');
      const loadingText = document.getElementById('loadingText');
      const loadingSubtext = document.getElementById('loadingSubtext');
      
      if (percentage !== null) {
        loadingBar.style.width = percentage + '%';
      }
      if (mainText !== null) {
        loadingText.textContent = mainText;
      }
      if (subText !== null) {
        loadingSubtext.textContent = subText;
      }
    }

    // function navigateToResult(data) { // This function is now removed.
    // // Store result data in sessionStorage
    // sessionStorage.setItem('poemResult', JSON.stringify(data));
    // window.location.href = '/result';
    // }

    async function processText(text) {
      try {
        showLoading();
        
        // Use EventSource for real-time updates
        const eventSource = new EventSource(`/api/process_text_stream?query=${encodeURIComponent(text)}`);
        
        let hasReceivedResult = false;
        
        eventSource.onmessage = function(event) {
          const data = JSON.parse(event.data);
          
          switch(data.type) {
            case 'status':
              if (data.message.includes("Searching for the top")) {
                updateLoadingProgress(5, data.message, "Seeking kindred spirits in rhyme...");
              } else if (data.message.includes("Scoring poems for relevance")) {
                updateLoadingProgress(10, data.message, "Consulting the muses for 22 verses...");
              } else if (data.message.includes("Selecting the perfect")) {
                updateLoadingProgress(95, data.message, "Selecting your soul's echo...");
              } else if (data.message.includes("Perfect match found")) {
                updateLoadingProgress(98, data.message, "Redirecting to your poem...");
              } else if (data.message.includes("Formatting")) {
                updateLoadingProgress(100, data.message, "Preparing your poem");
              } else {
                updateLoadingProgress(15, data.message, "Processing your request...");
              }
              break;
            case 'scoring':
              // Extract poem number from message like "Scoring poem 13/22: 'Title' by Author"
              const match = data.message.match(/Scoring poem (\d+)\/22:/);
              if (match) {
                const poemNumber = parseInt(match[1]);
                // Progress from 15% to 90% based on poem number (1-22)
                const progress = 15 + (poemNumber / 22) * 75; // 15% + (75% range)
                updateLoadingProgress(progress, "Evaluating poem relevance...", data.message);
              } else {
                updateLoadingProgress(50, "Evaluating poem relevance...", data.message);
              }
              break;
            case 'score':
              // Keep current progress, just update subtext with score
              updateLoadingProgress(null, null, data.message);
              break;
            case 'complete':
              hasReceivedResult = true;
              updateLoadingProgress(100, "Perfect match found!", "Revealing your poem...");

              loadingOverlay.style.opacity = '0';

              loadingOverlay.addEventListener('transitionend', function handleTransitionEnd(event) {
                if (event.propertyName === 'opacity' && loadingOverlay.style.opacity === '0') {
                  eventSource.close();
                  const resultData = JSON.parse(data.message);
                  if (resultData.success) {
                    sessionStorage.setItem('poemResult', JSON.stringify(resultData));
                    window.location.href = '/result';
                  } else {
                    loadingOverlay.style.opacity = '1'; // Show overlay again on error
                    alert('Error: ' + resultData.error);
                  }
                }
              }, { once: true });
              break;
            case 'error':
              // Restore opacity if overlay was fading out
              if (loadingOverlay.style.opacity === '0') {
                loadingOverlay.style.opacity = '1';
              }
              hideLoading(); // This will set display:none after a delay if opacity is still 0, or just reset opacity
              eventSource.close();
              alert('Error processing request: ' + data.message);
              break;
            case 'heartbeat':
              eventSource.close();
              alert('Error processing request: ' + data.message);
              break;
            case 'heartbeat':
              // Ignore heartbeat messages
              break;
          }
        };
        
        eventSource.onerror = function(event) {
          // Only show error if we haven't received a result yet
          if (!hasReceivedResult) {
            hideLoading();
            eventSource.close();
            alert('Connection error. Please try again.');
          }
        };
        
      } catch (error) {
        hideLoading();
        alert('Error processing request: ' + error.message);
      }
    }

    async function processAudio(audioBlob) {
      try {
        showLoading();
        updateLoadingProgress(5, "Transcribing your voice...", "Converting speech to text");
        
        // First, transcribe the audio
        const formData = new FormData();
        formData.append('audio', audioBlob, 'recording.webm');

        const transcribeResponse = await fetch('/api/transcribe_audio', {
          method: 'POST',
          body: formData
        });

        const transcribeData = await transcribeResponse.json();
        
        if (!transcribeData.success) {
          hideLoading();
          alert('Error: ' + transcribeData.error);
          return;
        }
        
        updateLoadingProgress(10, "Transcription complete", `"${transcribeData.transcription}"`);
        
        // Now process with streaming
        const eventSource = new EventSource(`/api/process_audio_stream?query=${encodeURIComponent(transcribeData.transcription)}`);
        
        let hasReceivedResult = false;
        
        eventSource.onmessage = function(event) {
          const data = JSON.parse(event.data);
          
          switch(data.type) {
            case 'status':
              if (data.message.includes("Searching for the top")) {
                updateLoadingProgress(15, data.message, "Seeking kindred spirits in rhyme...");
              } else if (data.message.includes("Scoring poems for relevance")) {
                updateLoadingProgress(20, data.message, "Consulting the muses for 22 verses...");
              } else if (data.message.includes("Selecting the perfect")) {
                updateLoadingProgress(95, data.message, "Selecting your soul's echo...");
              } else if (data.message.includes("Perfect match found")) {
                updateLoadingProgress(98, data.message, "Redirecting to your poem...");
              } else if (data.message.includes("Formatting")) {
                updateLoadingProgress(100, data.message, "Preparing your poem");
              } else {
                updateLoadingProgress(25, data.message, "Processing your transcription...");
              }
              break;
            case 'scoring':
              // Extract poem number from message like "Scoring poem 13/22: 'Title' by Author"
              const match = data.message.match(/Scoring poem (\d+)\/22:/);
              if (match) {
                const poemNumber = parseInt(match[1]);
                // Progress from 25% to 90% based on poem number (1-22)
                const progress = 25 + (poemNumber / 22) * 65; // 25% + (65% range)
                updateLoadingProgress(progress, "Evaluating poem relevance...", data.message);
              } else {
                updateLoadingProgress(60, "Evaluating poem relevance...", data.message);
              }
              break;
            case 'score':
              // Keep current progress, just update subtext with score
              updateLoadingProgress(null, null, data.message);
              break;
            case 'complete':
              hasReceivedResult = true;
              updateLoadingProgress(100, "Perfect match found!", "Revealing your poem...");

              loadingOverlay.style.opacity = '0';

              loadingOverlay.addEventListener('transitionend', function handleTransitionEnd(event) {
                if (event.propertyName === 'opacity' && loadingOverlay.style.opacity === '0') {
                  eventSource.close();
                  const resultData = JSON.parse(data.message);
                  if (resultData.success) {
                    sessionStorage.setItem('poemResult', JSON.stringify(resultData));
                    window.location.href = '/result';
                  } else {
                    loadingOverlay.style.opacity = '1'; // Show overlay again on error
                    alert('Error: ' + resultData.error);
                  }
                }
              }, { once: true });
              break;
            case 'error':
              // Restore opacity if overlay was fading out
              if (loadingOverlay.style.opacity === '0') {
                loadingOverlay.style.opacity = '1';
              }
              hideLoading(); // This will set display:none after a delay if opacity is still 0, or just reset opacity
              eventSource.close();
              alert('Error processing audio: ' + data.message);
              break;
            case 'heartbeat':
              eventSource.close();
              alert('Error processing audio: ' + data.message);
              break;
            case 'heartbeat':
              // Ignore heartbeat messages
              break;
          }
        };
        
        eventSource.onerror = function(event) {
          // Only show error if we haven't received a result yet
          if (!hasReceivedResult) {
            hideLoading();
            eventSource.close();
            alert('Connection error. Please try again.');
          }
        };
        
      } catch (error) {
        hideLoading();
        alert('Error processing audio: ' + error.message);
      }
    }

    attractBtn.addEventListener('click', async () => {
      if (currentMode === 'keyboard' && !expanded) {
        expanded = true;
        attractBtn.classList.add('expanded');
        attractBtn.innerHTML = `
          <textarea class="attract-textarea" placeholder="${getNextPrompt(true)}"></textarea>
          <div class="attract-bottom-bar">
            <button class="attract-submit-btn">Find My Verse</button>
          </div>
        `;
        const submitBtn = attractBtn.querySelector('.attract-submit-btn');
        const textarea = attractBtn.querySelector('.attract-textarea');
        
        submitBtn.addEventListener('click', () => {
          const text = textarea.value.trim();
          if (text) {
            processText(text);
          }
        });
        
        textarea.focus();
      } else if (currentMode === 'microphone' && !recording) {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          mediaRecorder = new MediaRecorder(stream);
          audioChunks = [];

          mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
          };

          mediaRecorder.onstop = () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            processAudio(audioBlob);
            stream.getTracks().forEach(track => track.stop());
          };

          mediaRecorder.start();
          recording = true;
          attractBtn.classList.add('recording');
          attractBtn.innerHTML = `
            <div class="recording-container">
              <div class="breathing-circle"></div>
            </div>
          `;
          
          setTimeout(() => {
            attractBtn.classList.add('hover-enabled');
          }, 3000);
          
          const recContainer = attractBtn.querySelector('.recording-container');
          recContainer.addEventListener('click', (e) => {
            e.stopPropagation();
            if (mediaRecorder && recording) {
              mediaRecorder.stop();
              recording = false;
              attractBtn.classList.remove('recording', 'hover-enabled');
              updateButtonText();
            }
          }, { once: true });
        } catch (error) {
          alert('Error accessing microphone: ' + error.message);
        }
      }
    });

    modeSpans.forEach(span => {
      span.addEventListener('click', () => {
        if (span.dataset.mode === currentMode) return;
        currentMode = span.dataset.mode;
        modeSpans.forEach(s => s.classList.toggle('selected', s.dataset.mode === currentMode));
        
        recording = false;
        expanded = false;
        attractBtn.classList.remove('recording', 'expanded', 'hover-enabled');
        updateButtonText();
      });
    });

    // Modal Toggle Logic
    const ourMethodTrigger = document.getElementById('ourMethodTrigger');
    const ourMethodModalOverlay = document.getElementById('ourMethodModalOverlay');
    const ourMethodModalCloseBtn = document.getElementById('ourMethodModalCloseBtn');
    const modalContent = ourMethodModalOverlay.querySelector('.modal-content');

    if (ourMethodTrigger && ourMethodModalOverlay && ourMethodModalCloseBtn) {
      ourMethodTrigger.addEventListener('click', () => {
        ourMethodModalOverlay.style.display = 'flex';
        setTimeout(() => { // Allow display flex to apply before transition
          ourMethodModalOverlay.style.opacity = '1';
          modalContent.style.transform = 'scale(1)';
        }, 10);
      });

      ourMethodModalCloseBtn.addEventListener('click', () => {
        ourMethodModalOverlay.style.opacity = '0';
        modalContent.style.transform = 'scale(0.95)';
        setTimeout(() => {
          ourMethodModalOverlay.style.display = 'none';
        }, 400); // Match transition duration
      });

      // Optional: Close modal if overlay is clicked
      ourMethodModalOverlay.addEventListener('click', (event) => {
        if (event.target === ourMethodModalOverlay) {
          ourMethodModalCloseBtn.click(); // Trigger close button logic
        }
      });
    }
  </script>
  <script>
    // Modal Toggle Logic for "Our Method"
    const ourMethodTrigger = document.getElementById('ourMethodTrigger');
    const ourMethodModalOverlay = document.getElementById('ourMethodModalOverlay');
    const ourMethodModalCloseBtn = document.getElementById('ourMethodModalCloseBtn');

    if (ourMethodTrigger && ourMethodModalOverlay && ourMethodModalCloseBtn) {
      const modalContent = ourMethodModalOverlay.querySelector('.modal-content'); // Get modalContent inside if
      ourMethodTrigger.addEventListener('click', () => {
        ourMethodModalOverlay.style.display = 'flex';
        setTimeout(() => { // Allow display flex to apply before transition
          ourMethodModalOverlay.style.opacity = '1';
          if (modalContent) modalContent.style.transform = 'scale(1)';
        }, 10);
      });

      const closeModal = () => {
        ourMethodModalOverlay.style.opacity = '0';
        if (modalContent) modalContent.style.transform = 'scale(0.95)';
        setTimeout(() => {
          ourMethodModalOverlay.style.display = 'none';
        }, 400); // Match transition duration
      };

      ourMethodModalCloseBtn.addEventListener('click', closeModal);

      // Optional: Close modal if overlay is clicked
      ourMethodModalOverlay.addEventListener('click', (event) => {
        if (event.target === ourMethodModalOverlay) {
          closeModal(); // Use the new closeModal function
        }
      });
    }
  </script>
</body>
</html> 